{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673c314e-33b4-403d-a537-b98550482b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ABLLW: Period '1mo' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 91\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_complete\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Generate the complete DataFrame for selected tickers\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m df_result \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m df_result\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m#df_result.to_csv(csv_file)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 86\u001b[0m, in \u001b[0;36mcreate_df\u001b[0;34m(tickers)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m---> 86\u001b[0m             df_complete \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_complete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_complete\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/project_env/lib/python3.10/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/project_env/lib/python3.10/site-packages/pandas/core/reshape/concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[1;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[0;32m--> 680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m    684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    686\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/project_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import csv\n",
    "\n",
    "# Get the list of NASDAQ companies\n",
    "nasdaq_tickers = pd.read_csv('nasdaq_screener.csv')\n",
    "tickers_total = nasdaq_tickers['Symbol'].tolist()\n",
    "tickers = tickers_total[20:30]\n",
    "\n",
    "# Prepare the CSV file\n",
    "csv_file = 'nasdaq_financial_data.csv'\n",
    "\n",
    "# Helper function to get the stock prices over a range of dates\n",
    "def get_stock_prices(ticker, start_date, end_date):\n",
    "    try:\n",
    "        stock_data = yf.Ticker(ticker).history(start=start_date, end=end_date)\n",
    "        return stock_data['Close']\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return pd.Series()\n",
    "\n",
    "# Compute the stock value ratio (item_stock%/sp500_stock%) in a year\n",
    "def get_stock_value_ratio(stock_prices, sp500_prices, date):\n",
    "    try:\n",
    "        if date not in stock_prices or date not in sp500_prices:\n",
    "            return None\n",
    "        date_diff = date - timedelta(weeks=52)\n",
    "        if date_diff not in stock_prices or date_diff not in sp500_prices:\n",
    "            return None\n",
    "        stock_change = stock_prices[date] / stock_prices[date_diff]\n",
    "        sp500_change = sp500_prices[date] / sp500_prices[date_diff]\n",
    "        return stock_change / sp500_change\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing ratio for date {date}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Flatten the data of a DataFrame\n",
    "def flatten_data(df, ticker):\n",
    "    df_u = df.unstack().reset_index()\n",
    "    df_u['Ticker'] = df_u.apply(lambda row: f\"{row['level_0'].year} {row['level_1']}\", axis=1)\n",
    "    df_u.set_index('Ticker', inplace=True)\n",
    "    df_ordered = df_u.drop(columns=['level_0', 'level_1'])\n",
    "    df_transposed = df_ordered.T\n",
    "    df_transposed['Ticker'] = ticker\n",
    "    return df_transposed\n",
    "\n",
    "# Function to get stock values and ratios for a DataFrame\n",
    "def get_stock_values_and_ratios(df, ticker, stock_prices, sp500_prices):\n",
    "    for date in df.columns:\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        stock_value = stock_prices.get(date_str, None)\n",
    "        ratio = get_stock_value_ratio(stock_prices, sp500_prices, date)\n",
    "        df.at['Stock value', date] = stock_value\n",
    "        df.at['Ratio ticker sp500', date] = ratio\n",
    "    return df\n",
    "\n",
    "# Create the complete DataFrame for all tickers\n",
    "def create_df(tickers):\n",
    "    df_complete = pd.DataFrame()\n",
    "    sp500_prices = get_stock_prices('^GSPC', datetime.now() - timedelta(weeks=52), datetime.now())\n",
    "    \n",
    "    def process_ticker(ticker):\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            balance_sheet = stock.balance_sheet\n",
    "            income_statement = stock.financials\n",
    "            cashflow_statement = stock.cashflow\n",
    "            \n",
    "            stock_prices = get_stock_prices(ticker, datetime.now() - timedelta(weeks=52), datetime.now())\n",
    "            df_bs = get_stock_values_and_ratios(balance_sheet, ticker, stock_prices, sp500_prices)\n",
    "            df_bs_f = flatten_data(df_bs, ticker)\n",
    "            df_is_f = flatten_data(income_statement, ticker)\n",
    "            df_cs_f = flatten_data(cashflow_statement, ticker)\n",
    "            df_row = pd.concat([df_bs_f, df_is_f, df_cs_f], axis=1)\n",
    "            return df_row\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing ticker {ticker}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(process_ticker, tickers)\n",
    "        for result in results:\n",
    "            if not result.empty:\n",
    "                df_complete = pd.concat([df_complete, result])\n",
    "    \n",
    "    return df_complete\n",
    "\n",
    "# Generate the complete DataFrame for selected tickers\n",
    "df_result = create_df(tickers)\n",
    "df_result\n",
    "#df_result.to_csv(csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30a9e61-15e8-412f-a0d1-4342dae8b890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ABLLW: Period '1mo' is invalid, must be one of ['1d', '5d']\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 98\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_complete\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Generate the complete DataFrame for selected tickers\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m df_result \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m df_result\u001b[38;5;241m.\u001b[39mto_csv(csv_file)\n",
      "Cell \u001b[0;32mIn[3], line 93\u001b[0m, in \u001b[0;36mcreate_df\u001b[0;34m(tickers)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m---> 93\u001b[0m             df_complete \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_complete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_complete\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/project_env/lib/python3.10/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/project_env/lib/python3.10/site-packages/pandas/core/reshape/concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[1;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[0;32m--> 680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m    684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    686\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/project_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Get the list of NASDAQ companies\n",
    "nasdaq_tickers = pd.read_csv('nasdaq_screener.csv')\n",
    "tickers_total = nasdaq_tickers['Symbol'].tolist()\n",
    "tickers = tickers_total[20:30]\n",
    "\n",
    "# Prepare the CSV file\n",
    "csv_file = 'nasdaq_financial_data.csv'\n",
    "\n",
    "# Helper function to get the stock prices over a range of dates\n",
    "def get_stock_prices(ticker, start_date, end_date):\n",
    "    try:\n",
    "        stock_data = yf.Ticker(ticker).history(start=start_date, end=end_date, interval='1d')\n",
    "        return stock_data['Close']\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return pd.Series()\n",
    "\n",
    "# Compute the stock value ratio (item_stock%/sp500_stock%) in a year\n",
    "def get_stock_value_ratio(stock_prices, sp500_prices, date):\n",
    "    try:\n",
    "        if date not in stock_prices or date not in sp500_prices:\n",
    "            return None\n",
    "        date_diff = date - timedelta(weeks=52)\n",
    "        if date_diff not in stock_prices or date_diff not in sp500_prices:\n",
    "            return None\n",
    "        stock_change = stock_prices[date] / stock_prices[date_diff]\n",
    "        sp500_change = sp500_prices[date] / sp500_prices[date_diff]\n",
    "        return stock_change / sp500_change\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing ratio for date {date}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Flatten the data of a DataFrame\n",
    "def flatten_data(df, ticker):\n",
    "    df = df.loc[:, ~df.columns.duplicated()]  # Remove duplicated columns\n",
    "    df_u = df.unstack().reset_index()\n",
    "    df_u['Ticker'] = df_u.apply(lambda row: f\"{row['level_0'].year} {row['level_1']}\", axis=1)\n",
    "    df_u.set_index('Ticker', inplace=True)\n",
    "    df_ordered = df_u.drop(columns=['level_0', 'level_1'])\n",
    "    df_transposed = df_ordered.T\n",
    "    df_transposed['Ticker'] = ticker\n",
    "    return df_transposed\n",
    "\n",
    "# Function to get stock values and ratios for a DataFrame\n",
    "def get_stock_values_and_ratios(df, ticker, stock_prices, sp500_prices):\n",
    "    for date in df.columns:\n",
    "        if isinstance(date, str):\n",
    "            date = datetime.strptime(date, '%Y-%m-%d')\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        stock_value = stock_prices.get(date_str, None)\n",
    "        ratio = get_stock_value_ratio(stock_prices, sp500_prices, date)\n",
    "        df.at['Stock value', date] = stock_value\n",
    "        df.at['Ratio ticker sp500', date] = ratio\n",
    "    return df\n",
    "\n",
    "# Create the complete DataFrame for all tickers\n",
    "def create_df(tickers):\n",
    "    df_complete = pd.DataFrame()\n",
    "    sp500_prices = get_stock_prices('^GSPC', datetime.now() - timedelta(weeks=52), datetime.now())\n",
    "    \n",
    "    def process_ticker(ticker):\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            balance_sheet = stock.balance_sheet\n",
    "            income_statement = stock.financials\n",
    "            cashflow_statement = stock.cashflow\n",
    "            \n",
    "            # Remove duplicate indices if any\n",
    "            balance_sheet = balance_sheet.loc[~balance_sheet.index.duplicated(keep='first')]\n",
    "            income_statement = income_statement.loc[~income_statement.index.duplicated(keep='first')]\n",
    "            cashflow_statement = cashflow_statement.loc[~cashflow_statement.index.duplicated(keep='first')]\n",
    "\n",
    "            stock_prices = get_stock_prices(ticker, datetime.now() - timedelta(weeks=52), datetime.now())\n",
    "            df_bs = get_stock_values_and_ratios(balance_sheet, ticker, stock_prices, sp500_prices)\n",
    "            df_bs_f = flatten_data(df_bs, ticker)\n",
    "            df_is_f = flatten_data(income_statement, ticker)\n",
    "            df_cs_f = flatten_data(cashflow_statement, ticker)\n",
    "            df_row = pd.concat([df_bs_f, df_is_f, df_cs_f], axis=1)\n",
    "            return df_row\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing ticker {ticker}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(process_ticker, tickers)\n",
    "        for result in results:\n",
    "            if not result.empty:\n",
    "                df_complete = pd.concat([df_complete, result])\n",
    "    \n",
    "    return df_complete\n",
    "\n",
    "# Generate the complete DataFrame for selected tickers\n",
    "df_result = create_df(tickers)\n",
    "df_result.to_csv(csv_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
